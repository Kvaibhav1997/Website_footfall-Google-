# -*- coding: utf-8 -*-
"""MS_DT_Assignment.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1vAK1seXGsHqHe-1zMPY6qi-kMqN_OZdf
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
from datetime import datetime
from sklearn.model_selection import train_test_split
from sklearn import tree
from sklearn import metrics
from sklearn import preprocessing
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import confusion_matrix
from sklearn.tree import DecisionTreeClassifier, export_graphviz
from sklearn.metrics import accuracy_score,classification_report,confusion_matrix
from sklearn.metrics import r2_score
from sklearn.metrics import mean_squared_error
import seaborn as sns
# %matplotlib inline
from math import sqrt
import matplotlib
import matplotlib.pyplot as plt
from sklearn.tree import export_graphviz
from sklearn.externals.six import StringIO  
from IPython.display import Image  
import pydotplus

#inporting the google drive to load the data 
from google.colab import drive
drive.mount('/content/drive')

#loading the dataset using path of the dataset in google drive
df = pd.read_csv('/content/drive/MyDrive/My Colab Dataset/ms_assignment.csv')

#viewing the first 5 rows of dataframe
df.head()

#checking if there is null value or not
df.isnull().sum()

df.shape

# describe method gives the detail informations about the numerical column
df.describe()

# replacing the null value with desired values. If total_bounces = 1, then no transaction; else a transaction is made, so we replace NaN with 0
df['bounces'].fillna(0, inplace=True)
# if totals_pageviews = NaN, there will be no transaction; else transaction is made, so we replace NaN with 0
df['pageviews'].fillna(0, inplace=True)
# if totals_timeOnSite = NaN,there will be no transaction; else transaction is made, so we replace NaN with 0
df['timeOnSite'].fillna(0, inplace=True)
#converting the column into datetime
df['VisitStartTime'] = pd.to_datetime(df['VisitStartTime'],unit='s')

# replacing "not available in demo dataset" and "(not set)" by "Unavailable"
df['city'].replace('not available in demo dataset', 'Unavailable', inplace=True)
df['city'].replace('(not set)', 'Unavailable', inplace=True)

# extracting year, month, day, hour, minute from date
df['year'] = df['VisitStartTime'].dt.year
df['month'] = df['VisitStartTime'].dt.month
df['day'] = df['VisitStartTime'].dt.day
df['hour'] = df['VisitStartTime'].dt.hour
df['minute'] = df['VisitStartTime'].dt.minute

#checking Transaction_revenue and Transactions
for i in range(0, len(df), 1):
    if (pd.isna(df.iloc[i, 7])) and (pd.notna(df.iloc[i, 8])):
        print('ERROR: totalTransactionRevenue missing when transactions not null at row ', i)
    if (pd.isna(df.iloc[i, 8])) and (pd.notna(df.iloc[i, 7])):
        print('ERROR: transactions missing when totalTransactionRevenue is not null at row ', i)

#replacing the null values with required values
df['totalTransactionRevenue'].fillna(0,inplace=True)
df['transactions'].fillna(0,inplace=True)

# creating a new column where if transaction data contain 0 means no transaction is happened and if it contain 1, it mean transaction is happened
df['transaction'] = np.where(df['transactions']  == 0, 0, 1)

#checking the counts of repetitive values in the transaction column
df['transaction'].value_counts()

# TransactionRevenue is totalTransactionRevenue is divided by 10^6
df['transactionRevenue'] = df['totalTransactionRevenue'] / 1000000

#removing the unwanted columns
df = df.drop(['VisitStartTime','totalTransactionRevenue','year','fullVisitorId', 'Date', 'mobileDeviceModel', 'transactions'],axis=1)

df.head(10)

#from the heatmap We get the corelation between the similar tables
fig1 = plt.figure(figsize = (16,12));
plt.title('Correlation Matrix')
df.corr()
sns.heatmap(df.corr(), vmin = -1, vmax = 1,  cmap = 'YlGnBu', annot=True);
plt.xticks(rotation=90)
plt.yticks(rotation=0)
plt.show()

#plotted the graph of pageviews vs timeonsite(seconds) under the consideration of transactions
plt.figure(figsize=(25,8))
sns.scatterplot(x='timeOnSite', y='pageviews', hue='transaction', data=df)
plt.xticks(fontsize=15)
plt.yticks(fontsize=15)
plt.xlabel('Time taken on site in seconds', fontsize=20)
plt.ylabel("Count of page views", fontsize=20)
plt.show()

"""All the greater proportion of transactions that have made in the starting hours i.e. upto 6000sec."""

#this gives the information about the whole table like datatypes, counts and nullvalues
df.info()

#To convert categorical variables to integer using label encoder
le= LabelEncoder()
df['ChannelGrouping']=le.fit_transform(df['ChannelGrouping'])
df['city']=le.fit_transform(df['city'])
df['operatingSystem']=le.fit_transform(df['operatingSystem'])
df['ChannelGrouping']=le.fit_transform(df['ChannelGrouping'])
df['source']=le.fit_transform(df['source'])
df['medium']=le.fit_transform(df["medium"])
df['campaign']=le.fit_transform(df['campaign'])
df['deviceCategory']=le.fit_transform(df['deviceCategory'])

df.hist(figsize=(28,20), bins=30)
plt.show()

features = ['VisitNumber', 'bounces', 'pageviews', 'timeOnSite', 'source','medium', 'campaign', 'operatingSystem', 'city', 'ChannelGrouping', 'month', 'day', 'hour', 'deviceCategory']

x = df[features]
y = df[['transaction']]

print("Shape of features:", x.shape)
print("Shape of target:", y.shape)

# Spliting the data into training set and testing set in 80:20 ratio
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2)

clf = DecisionTreeClassifier()
clf = clf.fit(x_train,y_train)

#Predict for test dataset
y_pred = clf.predict(x_test)

# generating confusion matrix
confusion_matrix(y_test, y_pred)

y_pred[0:5]

y_test[0:5]

print("Accuracy is: {} % ".format(metrics.accuracy_score(y_test, y_pred)*100) )
print("Classification Report is:\n",classification_report(y_test,y_pred))
print("Confusion Matrix: \n",(confusion_matrix(y_test,y_pred)))
print("Training Score: {} %".format(clf.score(x_train,y_train)*100))
print("Root Mean Squared Error: {}".format(sqrt(mean_squared_error(y_test,y_pred))))

from sklearn.ensemble import RandomForestClassifier

#plotting the graph of Decision Tree, here we see like a straight line but it contain 1000's of branches.
dot_data = StringIO()
export_graphviz(clf, out_file=dot_data,  
                filled=True, rounded=True,
                special_characters=True,feature_names = features,class_names=['0','1'])
graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  
graph.write_png('image.png')
Image(graph.create_png())